{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sidmitta/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install bs4 # in case you don't have it installed\n",
    "\n",
    "# Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Kitchen_v1_00.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 16148: expected 15 fields, saw 22\\nSkipping line 20100: expected 15 fields, saw 22\\nSkipping line 45178: expected 15 fields, saw 22\\nSkipping line 48700: expected 15 fields, saw 22\\nSkipping line 63331: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 86053: expected 15 fields, saw 22\\nSkipping line 88858: expected 15 fields, saw 22\\nSkipping line 115017: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 137366: expected 15 fields, saw 22\\nSkipping line 139110: expected 15 fields, saw 22\\nSkipping line 165540: expected 15 fields, saw 22\\nSkipping line 171813: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 203723: expected 15 fields, saw 22\\nSkipping line 209366: expected 15 fields, saw 22\\nSkipping line 211310: expected 15 fields, saw 22\\nSkipping line 246351: expected 15 fields, saw 22\\nSkipping line 252364: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 267003: expected 15 fields, saw 22\\nSkipping line 268957: expected 15 fields, saw 22\\nSkipping line 303336: expected 15 fields, saw 22\\nSkipping line 306021: expected 15 fields, saw 22\\nSkipping line 311569: expected 15 fields, saw 22\\nSkipping line 316767: expected 15 fields, saw 22\\nSkipping line 324009: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 359107: expected 15 fields, saw 22\\nSkipping line 368367: expected 15 fields, saw 22\\nSkipping line 381180: expected 15 fields, saw 22\\nSkipping line 390453: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 412243: expected 15 fields, saw 22\\nSkipping line 419342: expected 15 fields, saw 22\\nSkipping line 457388: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 459935: expected 15 fields, saw 22\\nSkipping line 460167: expected 15 fields, saw 22\\nSkipping line 466460: expected 15 fields, saw 22\\nSkipping line 500314: expected 15 fields, saw 22\\nSkipping line 500339: expected 15 fields, saw 22\\nSkipping line 505396: expected 15 fields, saw 22\\nSkipping line 507760: expected 15 fields, saw 22\\nSkipping line 513626: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 527638: expected 15 fields, saw 22\\nSkipping line 534209: expected 15 fields, saw 22\\nSkipping line 535687: expected 15 fields, saw 22\\nSkipping line 547671: expected 15 fields, saw 22\\nSkipping line 549054: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 599929: expected 15 fields, saw 22\\nSkipping line 604776: expected 15 fields, saw 22\\nSkipping line 609937: expected 15 fields, saw 22\\nSkipping line 632059: expected 15 fields, saw 22\\nSkipping line 638546: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 665017: expected 15 fields, saw 22\\nSkipping line 677680: expected 15 fields, saw 22\\nSkipping line 684370: expected 15 fields, saw 22\\nSkipping line 720217: expected 15 fields, saw 29\\n'\n",
      "b'Skipping line 723240: expected 15 fields, saw 22\\nSkipping line 723433: expected 15 fields, saw 22\\nSkipping line 763891: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 800288: expected 15 fields, saw 22\\nSkipping line 802942: expected 15 fields, saw 22\\nSkipping line 803379: expected 15 fields, saw 22\\nSkipping line 805122: expected 15 fields, saw 22\\nSkipping line 821899: expected 15 fields, saw 22\\nSkipping line 831707: expected 15 fields, saw 22\\nSkipping line 842829: expected 15 fields, saw 22\\nSkipping line 843604: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 863904: expected 15 fields, saw 22\\nSkipping line 875655: expected 15 fields, saw 22\\nSkipping line 886796: expected 15 fields, saw 22\\nSkipping line 892299: expected 15 fields, saw 22\\nSkipping line 902518: expected 15 fields, saw 22\\nSkipping line 903079: expected 15 fields, saw 22\\nSkipping line 912678: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 932953: expected 15 fields, saw 22\\nSkipping line 936838: expected 15 fields, saw 22\\nSkipping line 937177: expected 15 fields, saw 22\\nSkipping line 947695: expected 15 fields, saw 22\\nSkipping line 960713: expected 15 fields, saw 22\\nSkipping line 965225: expected 15 fields, saw 22\\nSkipping line 980776: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 999318: expected 15 fields, saw 22\\nSkipping line 1007247: expected 15 fields, saw 22\\nSkipping line 1015987: expected 15 fields, saw 22\\nSkipping line 1018984: expected 15 fields, saw 22\\nSkipping line 1028671: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1063360: expected 15 fields, saw 22\\nSkipping line 1066195: expected 15 fields, saw 22\\nSkipping line 1066578: expected 15 fields, saw 22\\nSkipping line 1066869: expected 15 fields, saw 22\\nSkipping line 1068809: expected 15 fields, saw 22\\nSkipping line 1069505: expected 15 fields, saw 22\\nSkipping line 1087983: expected 15 fields, saw 22\\nSkipping line 1108184: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1118137: expected 15 fields, saw 22\\nSkipping line 1142723: expected 15 fields, saw 22\\nSkipping line 1152492: expected 15 fields, saw 22\\nSkipping line 1156947: expected 15 fields, saw 22\\nSkipping line 1172563: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1209254: expected 15 fields, saw 22\\nSkipping line 1212966: expected 15 fields, saw 22\\nSkipping line 1236533: expected 15 fields, saw 22\\nSkipping line 1237598: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1273825: expected 15 fields, saw 22\\nSkipping line 1277898: expected 15 fields, saw 22\\nSkipping line 1283654: expected 15 fields, saw 22\\nSkipping line 1286023: expected 15 fields, saw 22\\nSkipping line 1302038: expected 15 fields, saw 22\\nSkipping line 1305179: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1326022: expected 15 fields, saw 22\\nSkipping line 1338120: expected 15 fields, saw 22\\nSkipping line 1338503: expected 15 fields, saw 22\\nSkipping line 1338849: expected 15 fields, saw 22\\nSkipping line 1341513: expected 15 fields, saw 22\\nSkipping line 1346493: expected 15 fields, saw 22\\nSkipping line 1373127: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1389508: expected 15 fields, saw 22\\nSkipping line 1413951: expected 15 fields, saw 22\\nSkipping line 1433626: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1442698: expected 15 fields, saw 22\\nSkipping line 1472982: expected 15 fields, saw 22\\nSkipping line 1482282: expected 15 fields, saw 22\\nSkipping line 1487808: expected 15 fields, saw 22\\nSkipping line 1500636: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1511479: expected 15 fields, saw 22\\nSkipping line 1532302: expected 15 fields, saw 22\\nSkipping line 1537952: expected 15 fields, saw 22\\nSkipping line 1539951: expected 15 fields, saw 22\\nSkipping line 1541020: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1594217: expected 15 fields, saw 22\\nSkipping line 1612264: expected 15 fields, saw 22\\nSkipping line 1615907: expected 15 fields, saw 22\\nSkipping line 1621859: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1653542: expected 15 fields, saw 22\\nSkipping line 1671537: expected 15 fields, saw 22\\nSkipping line 1672879: expected 15 fields, saw 22\\nSkipping line 1674523: expected 15 fields, saw 22\\nSkipping line 1677355: expected 15 fields, saw 22\\nSkipping line 1703907: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1713046: expected 15 fields, saw 22\\nSkipping line 1722982: expected 15 fields, saw 22\\nSkipping line 1727290: expected 15 fields, saw 22\\nSkipping line 1744482: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1803858: expected 15 fields, saw 22\\nSkipping line 1810069: expected 15 fields, saw 22\\nSkipping line 1829751: expected 15 fields, saw 22\\nSkipping line 1831699: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1863131: expected 15 fields, saw 22\\nSkipping line 1867917: expected 15 fields, saw 22\\nSkipping line 1874790: expected 15 fields, saw 22\\nSkipping line 1879952: expected 15 fields, saw 22\\nSkipping line 1880501: expected 15 fields, saw 22\\nSkipping line 1886655: expected 15 fields, saw 22\\nSkipping line 1887888: expected 15 fields, saw 22\\nSkipping line 1894286: expected 15 fields, saw 22\\nSkipping line 1895400: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1904040: expected 15 fields, saw 22\\nSkipping line 1907604: expected 15 fields, saw 22\\nSkipping line 1915739: expected 15 fields, saw 22\\nSkipping line 1921514: expected 15 fields, saw 22\\nSkipping line 1939428: expected 15 fields, saw 22\\nSkipping line 1944342: expected 15 fields, saw 22\\nSkipping line 1949699: expected 15 fields, saw 22\\nSkipping line 1961872: expected 15 fields, saw 22\\n'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1968846: expected 15 fields, saw 22\\nSkipping line 1999941: expected 15 fields, saw 22\\nSkipping line 2001492: expected 15 fields, saw 22\\nSkipping line 2011204: expected 15 fields, saw 22\\nSkipping line 2025295: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2041266: expected 15 fields, saw 22\\nSkipping line 2073314: expected 15 fields, saw 22\\nSkipping line 2080133: expected 15 fields, saw 22\\nSkipping line 2088521: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2103490: expected 15 fields, saw 22\\nSkipping line 2115278: expected 15 fields, saw 22\\nSkipping line 2153174: expected 15 fields, saw 22\\nSkipping line 2161731: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2165250: expected 15 fields, saw 22\\nSkipping line 2175132: expected 15 fields, saw 22\\nSkipping line 2206817: expected 15 fields, saw 22\\nSkipping line 2215848: expected 15 fields, saw 22\\nSkipping line 2223811: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2257265: expected 15 fields, saw 22\\nSkipping line 2259163: expected 15 fields, saw 22\\nSkipping line 2263291: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2301943: expected 15 fields, saw 22\\nSkipping line 2304371: expected 15 fields, saw 22\\nSkipping line 2306015: expected 15 fields, saw 22\\nSkipping line 2312186: expected 15 fields, saw 22\\nSkipping line 2314740: expected 15 fields, saw 22\\nSkipping line 2317754: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2383514: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2449763: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2589323: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2775036: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2935174: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 3078830: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 3123091: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 3185533: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 4150395: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 4748401: expected 15 fields, saw 22\\n'\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('amazon_reviews_us_Kitchen_v1_00.tsv', sep='\\t', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Reviews and Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         review_body  star_rating\n",
      "0                Beautiful.  Looks great on counter.          5.0\n",
      "1  I personally have 5 days sets and have also bo...          5.0\n",
      "2  Fabulous and worth every penny. Used for clean...          5.0\n",
      "The counts for positive, negative and neutral reviews are: 3856492, 668848, 349547\n",
      "Number of reviews with rating 1 =  426900\n",
      "Number of reviews with rating 2 =  241948\n",
      "Number of reviews with rating 3 =  349547\n",
      "Number of reviews with rating 4 =  731733\n",
      "Number of reviews with rating 5 =  3124759\n"
     ]
    }
   ],
   "source": [
    "data = dataset[['review_body', 'star_rating']]\n",
    "\n",
    "#Printing 3 sample reviews with ratings and count of reviews for each rating\n",
    "print(data.iloc[:3])\n",
    "\n",
    "Positive = data['star_rating'][(data['star_rating']>3.0)].count()\n",
    "Negative = data['star_rating'][(data['star_rating']<3.0)].count()\n",
    "Neutral = data['star_rating'][(data['star_rating']==3.0)].count()\n",
    "\n",
    "print(\"The counts for positive, negative and neutral reviews are: \" +str(Positive)+\", \"+str(Negative)+\", \"+str(Neutral))\n",
    "\n",
    "ratings_1 = data['star_rating'][(data['star_rating']==1.0)].count()\n",
    "print('Number of reviews with rating 1 = ', ratings_1)\n",
    "\n",
    "ratings_2 = data['star_rating'][(data['star_rating']==2.0)].count()\n",
    "print('Number of reviews with rating 2 = ', ratings_2)\n",
    "\n",
    "ratings_3 = data['star_rating'][(data['star_rating']==3.0)].count()\n",
    "print('Number of reviews with rating 3 = ', ratings_3)\n",
    "\n",
    "ratings_4 = data['star_rating'][(data['star_rating']==4.0)].count()\n",
    "print('Number of reviews with rating 4 = ', ratings_4)\n",
    "\n",
    "ratings_5 = data['star_rating'][(data['star_rating']==5.0)].count()\n",
    "print('Number of reviews with rating 5 = ', ratings_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelling Reviews:\n",
    "## The reviews with rating 4,5 are labelled to be 1 and 1,2 are labelled as 0. Discard the reviews with rating 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidmitta/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df = data[data['star_rating'] !=3]\n",
    "df['star_rating'] = df['star_rating'].apply(lambda x: 1 if x > 3 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## We select 200000 reviews randomly with 100,000 positive and 100,000 negative reviews.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.query(' star_rating == 1').sample(n=100000)\n",
    "df2 = df.query(' star_rating == 0').sample(n=100000)\n",
    "frames = [df1, df2]\n",
    "df = pd.concat(frames)\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "## Convert the all reviews into the lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review_body\"] = df['review_body'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove the HTML and URLs from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4720200</th>\n",
       "      <td>i wanted a grill for making myself hamburgers ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208050</th>\n",
       "      <td>i love this water bottle.  i bought two at the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389475</th>\n",
       "      <td>great product. i use this all the time. sturdy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924830</th>\n",
       "      <td>the area great</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4063055</th>\n",
       "      <td>we just received these as a gift, but they arr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_body  star_rating\n",
       "4720200  i wanted a grill for making myself hamburgers ...            0\n",
       "4208050  i love this water bottle.  i bought two at the...            1\n",
       "1389475  great product. i use this all the time. sturdy...            1\n",
       "924830                                      the area great            1\n",
       "4063055  we just received these as a gift, but they arr...            0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_rows = len(df['review_body'])\n",
    "len_before_cleaning = df['review_body'].apply(lambda x: len(x) if type(x).__name__== 'str' else 0).mean()\n",
    "\n",
    "df['review_body'] = df['review_body'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n",
    "\n",
    "import re\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "  cleanr = re.compile('<.*?>')\n",
    "  cleantext = re.sub(cleanr, ' ', raw_html)\n",
    "  return cleantext\n",
    "\n",
    "df['review_body'] = df['review_body'].apply(lambda x: cleanhtml(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove non-alphabetical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4720200    i wanted a grill for making myself hamburgers ...\n",
       "4208050    i love this water bottle  i bought two at the ...\n",
       "1389475    great product i use this all the time sturdy a...\n",
       "924830                                        the area great\n",
       "4063055    we just received these as a gift but they arri...\n",
       "4550586    i love this little italian delight  i use it e...\n",
       "2289117    i have yet to learn how this item works  it is...\n",
       "3681275    about the best thing i can say about this toas...\n",
       "1074225    this mat is fantastic i was concerned initiall...\n",
       "1366179                      nice glasses hand fit is superb\n",
       "1994496    well my friend r happy with the gifts but it w...\n",
       "4604381    the glass container really sets this blender a...\n",
       "704130     the worst pan i have ever owned everything sti...\n",
       "4676115    ok its another unnecessary kitchen gadget but ...\n",
       "2434613    had to send it back because it was defective  ...\n",
       "477506     after a two minute learning curve we are now u...\n",
       "2954880    i love these contigo travel cups  i purchased ...\n",
       "656597     works fine in every way  they improved the pou...\n",
       "3285846    excited to get the larger capacity only to fin...\n",
       "3789461    the fd dehydrator that these trays fit can han...\n",
       "2046302    two of the steak knives have broken in half in...\n",
       "4039179    i agree with a previous reviewer the poor desi...\n",
       "2575257    i love how these just stick together when in t...\n",
       "1417677    got this for my girlfriend and she loves it  w...\n",
       "1036661    what is the warranty on this cheese slicer  ge...\n",
       "1655911                                              love it\n",
       "206674        box doesnt open worth a s but love the product\n",
       "3077014    it has pretty good materials is easy to use an...\n",
       "4066733    i do not like these pens they never work they ...\n",
       "1433623                three ties missing but otherwise fine\n",
       "                                 ...                        \n",
       "1399207    these glasses are gorgeous very classy my husb...\n",
       "4125250    the zero water system is a nice system if you ...\n",
       "804348     great replacement for the other black and deck...\n",
       "2452311    good quality frame with spring hinged make fit...\n",
       "4403387    purchased  sets for gifts i did check out one ...\n",
       "1471639              these have been terrific  very nice set\n",
       "1790608    the description said this was  it is only  lon...\n",
       "3702199    love it this is just the right size for cookin...\n",
       "1816729    i replaced my lodge cast iron pan with this on...\n",
       "4157415    i tried this pan with high hopes  the cakes tu...\n",
       "2235636    my daughter loves sesame street so i was excit...\n",
       "539240                                           love my mug\n",
       "1176304    product is  not all made in usa inside ring un...\n",
       "2163763    i had bought this item as a gift for someone b...\n",
       "3063356    i seen this on rachel rays show so i bought on...\n",
       "647191                                worst pots i ever used\n",
       "2182630    this gets two stars because functionally this ...\n",
       "2781628    ive had this can opener for about  months and ...\n",
       "2512946    i received this lunch pail after waiting for a...\n",
       "4683606    ive had this set for about a month now  i repl...\n",
       "3150777    used these recently for a college football tai...\n",
       "1817008    i purchased this product as it was  the price ...\n",
       "953214                                        gave as a gift\n",
       "4213879    this was actually a gift for a friend we desig...\n",
       "4428229    i was disappointed with the quality if this pr...\n",
       "1277899    do not like it and the price was quite high  i...\n",
       "3741390    i love my new kitchen scissors  they fit all m...\n",
       "1043712                          poor quality broke returned\n",
       "3912621    i was excited to get this but when it arrived ...\n",
       "2548079    i am so disappointed they tip over much easier...\n",
       "Name: review_body, Length: 200000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_body'].str.replace('[^ a-zA-Z]', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the extra spaces between the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4720200</th>\n",
       "      <td>i wanted a grill for making myself hamburgers ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208050</th>\n",
       "      <td>i love this water bottle. i bought two at the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389475</th>\n",
       "      <td>great product. i use this all the time. sturdy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924830</th>\n",
       "      <td>the area great</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4063055</th>\n",
       "      <td>we just received these as a gift, but they arr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_body  star_rating\n",
       "4720200  i wanted a grill for making myself hamburgers ...            0\n",
       "4208050  i love this water bottle. i bought two at the ...            1\n",
       "1389475  great product. i use this all the time. sturdy...            1\n",
       "924830                                      the area great            1\n",
       "4063055  we just received these as a gift, but they arr...            0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_body'] = df['review_body'].replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform contractions on the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length before and after cleaning text 323.428 , 320.139\n"
     ]
    }
   ],
   "source": [
    "def contractionfunction(phrase):\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "df['review_body'] = df.review_body.apply(lambda row: contractionfunction(row))\n",
    "\n",
    "len_after_cleaning = df['review_body'].apply(lambda x: len(x) if type(x).__name__== 'str' else 0).mean()\n",
    "print('Length before and after cleaning text %.3f' %len_before_cleaning,', %.3f'%len_after_cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove the stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "len_before_preprcessing = df['review_body'].apply(lambda x: len(x) if type(x).__name__== 'str' else 0).mean()\n",
    "stop = stopwords.words('english')\n",
    "df['review_body'] = df['review_body'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform lemmatization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length before and after pre-processing text 320.139 , 213.265\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    return lemmatized_output\n",
    "\n",
    "df['review_body'] = df.review_body.apply(lambda x: lemmatize_text(x))\n",
    "len_after_preprcessing = df['review_body'].apply(lambda x: len(x) if type(x).__name__== 'str' else 0).mean()\n",
    "print('Length before and after pre-processing text %.3f' %len_before_preprcessing,', %.3f'%len_after_preprcessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidmitta/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['review_body'])\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, df['star_rating'],test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.899 0.885 0.917 0.901 0.860 0.847 0.878 0.862\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(train_X, train_Y)\n",
    "\n",
    "perceptron_pred_train = clf.predict(train_X)\n",
    "perceptron_pred_test = clf.predict(test_X)\n",
    "\n",
    "print('%.3f' % accuracy_score(train_Y, perceptron_pred_train),\n",
    "      '%.3f' % precision_score(train_Y, perceptron_pred_train),\n",
    "      '%.3f' % recall_score(train_Y, perceptron_pred_train),\n",
    "      '%.3f' % f1_score(train_Y, perceptron_pred_train),\n",
    "      '%.3f' % accuracy_score(test_Y, perceptron_pred_test),\n",
    "      '%.3f' % precision_score(test_Y, perceptron_pred_test),\n",
    "      '%.3f' % recall_score(test_Y, perceptron_pred_test),\n",
    "      '%.3f' % f1_score(test_Y, perceptron_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936 0.937 0.934 0.936 0.898 0.900 0.895 0.897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "clf_svm = LinearSVC(random_state=0, tol=1e-5).fit(train_X, train_Y)\n",
    "svm_pred_train = clf_svm.predict(train_X)\n",
    "svm_pred_test = clf_svm.predict(test_X)\n",
    "\n",
    "print('%.3f' % accuracy_score(train_Y, svm_pred_train),\n",
    "      '%.3f' % precision_score(train_Y, svm_pred_train),\n",
    "      '%.3f' % recall_score(train_Y, svm_pred_train),\n",
    "      '%.3f' % f1_score(train_Y, svm_pred_train),\n",
    "      '%.3f' % accuracy_score(test_Y, svm_pred_test),\n",
    "      '%.3f' % precision_score(test_Y, svm_pred_test),\n",
    "      '%.3f' % recall_score(test_Y, svm_pred_test),\n",
    "      '%.3f' % f1_score(test_Y, svm_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916 0.919 0.912 0.916 0.900 0.903 0.896 0.899\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(train_X, train_Y)\n",
    "\n",
    "lg_train_prediction = clf.predict(train_X)\n",
    "lg_test_prediction = clf.predict(test_X)\n",
    "\n",
    "print('%.3f' % accuracy_score(train_Y, lg_train_prediction),\n",
    "      '%.3f' % precision_score(train_Y, lg_train_prediction),\n",
    "      '%.3f' % recall_score(train_Y, lg_train_prediction),\n",
    "      '%.3f' % f1_score(train_Y, lg_train_prediction),\n",
    "      '%.3f' % accuracy_score(test_Y, lg_test_prediction),\n",
    "      '%.3f' % precision_score(test_Y, lg_test_prediction),\n",
    "      '%.3f' % recall_score(test_Y, lg_test_prediction),\n",
    "      '%.3f' % f1_score(test_Y, lg_test_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.889, 0.895 0.882 0.888 0.873 0.878 0.865 0.871\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_X, train_Y)\n",
    "\n",
    "nb_train_prediction = clf.predict(train_X)\n",
    "nb_test_prediction = clf.predict(test_X)\n",
    "\n",
    "print('%.3f,' % accuracy_score(train_Y, nb_train_prediction),\n",
    "      '%.3f,' % precision_score(train_Y, nb_train_prediction),\n",
    "      '%.3f,' % recall_score(train_Y, nb_train_prediction),\n",
    "      '%.3f,' % f1_score(train_Y, nb_train_prediction),\n",
    "      '%.3f,' % accuracy_score(test_Y, nb_test_prediction),\n",
    "      '%.3f,' % precision_score(test_Y, nb_test_prediction),\n",
    "      '%.3f,' % recall_score(test_Y, nb_test_prediction),\n",
    "      '%.3f' % f1_score(test_Y, nb_test_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
